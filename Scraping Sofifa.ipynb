{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUNNING ALL FUNCTIONS AND IMPORTS\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "#Making Soup function\n",
    "def soup_making(url):\n",
    "    my_page = requests.get(url)\n",
    "    soup = bs(my_page.text, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "#getting the text function\n",
    "def get_text(my_list):\n",
    "    data = []\n",
    "    for item in my_list:\n",
    "        data.append(item.getText())\n",
    "    return data\n",
    "\n",
    "#finds all classes for a given tag\n",
    "def find_all_classes(my_soup,tag):\n",
    "    tags = my_soup.find_all(tag)\n",
    "    all_td_classes = set()\n",
    "    for tag in tags:\n",
    "        for c in tag.attrs['class']:\n",
    "            all_td_classes.add(c)\n",
    "    return list(all_td_classes)\n",
    "\n",
    "#creating a dict with classes names as Keys and the texts as values\n",
    "def create_dict(my_soup,classes):\n",
    "    data_dict = {}\n",
    "    for item in classes:\n",
    "        values = get_text(my_soup.find_all('td',{'class':item}))\n",
    "        data_dict.update({item:values})\n",
    "    return data_dict\n",
    "\n",
    "#clean given string\n",
    "def clean_string(my_list,string):\n",
    "    data =[]\n",
    "    for item in my_list:\n",
    "        a = re.sub(string,'',item)\n",
    "        data.append(a)\n",
    "    return data\n",
    "\n",
    "#remove undesired classes\n",
    "def remove_from_my_classes(my_classes,classes_to_remove):\n",
    "    for x in classes_to_remove:\n",
    "        my_classes.remove(x)\n",
    "    return my_classes\n",
    "\n",
    "#creates a list of urls to iterate\n",
    "def create_urls_list(url,indexes):\n",
    "    urls_list = []\n",
    "    for index in indexes:\n",
    "        current_url = url + str(index)\n",
    "        urls_list.append(current_url)\n",
    "    return urls_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING all the URLS\n",
    "#generating url indexes\n",
    "indexes = np.arange(0,17400,60)\n",
    "url = 'https://sofifa.com/players? showCol%5B0%5D=pi&showCol%5B1%5D=ae&showCol%5B2%5D=oa&showCol%5B3%5D=pt&showCol%5B4%5D=bp&showCol%5B5%5D=gu&showCol%5B6%5D=le&showCol%5B7%5D=vl&showCol%5B8%5D=wg&showCol%5B9%5D=tt&showCol%5B10%5D=pac&showCol%5B11%5D=sho&showCol%5B12%5D=pas&showCol%5B13%5D=dri&showCol%5B14%5D=def&showCol%5B15%5D=phy&offset='\n",
    "urls = create_urls_list(url,indexes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION THAT SCRAPES ALL SOFIFA PAGES\n",
    "def create_final_df(urls):\n",
    "    df_list = []\n",
    "    for url in urls:\n",
    "        my_dict = {}\n",
    "        soup = soup_making(url)\n",
    "        my_classes = find_all_classes(soup,'td')\n",
    "        classes_to_remove = ['col','col-avatar','col-comment','col-name']\n",
    "        my_classes = remove_from_my_classes(my_classes,classes_to_remove)\n",
    "        my_dict = create_dict(soup, my_classes)\n",
    "        #~~~~~~getting team, name and contract\n",
    "        #CONTRACT\n",
    "        contract = soup.find_all('div',{'class':'sub'})\n",
    "        contract = get_text(contract)\n",
    "        contract = clean_string(contract,'\\n*')\n",
    "        #NAME AND TEAM\n",
    "        name_team_contract = soup.find_all('div',{'class':'bp3-text-overflow-ellipsis'})\n",
    "        name_team_contract = get_text(name_team_contract)\n",
    "        #NAME\n",
    "        name = name_team_contract[::2]\n",
    "        name = clean_string(name,'\\\\d|\\~')\n",
    "        #TEAM\n",
    "        team = name_team_contract[1::2]\n",
    "        team = clean_string(team,'\\n*|\\\\d|\\~')\n",
    "        #adding them to the dict\n",
    "        my_dict['Contract'] = contract\n",
    "        my_dict['Name'] = name\n",
    "        my_dict['Team'] = team\n",
    "        df = pd.DataFrame(my_dict)\n",
    "        df_list.append(df)\n",
    "        sleep(randint(2,10))\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "final_df = create_final_df(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col-pt col-pas col-bp        col-le col-gu col-vl col-sho col-tt col-pac  \\\n",
      "0      81      64     ST  Jun 30, 2021      7  €8.5M      73   1873      82   \n",
      "1      71      61     ST           N/A      2     €0      67   1716      73   \n",
      "2      84      69    CAM           N/A     10  €9.5M      64   1873      79   \n",
      "3      75      57     GK           N/A      4    €2M      66   1141      78   \n",
      "4      83      79    CAM           N/A      5   €21M      71   2052      74   \n",
      "..    ...     ...    ...           ...    ...    ...     ...    ...     ...   \n",
      "55     73      60     ST           N/A      5  €1.8M      69   1725      77   \n",
      "56     69      58    CDM           N/A      3  €1.1M      50   1740      70   \n",
      "57     70      57    CDM           N/A     10  €550K      46   1586      52   \n",
      "58     76      65    CAM           N/A     16  €650K      51   1547      65   \n",
      "59     70      40     CB           N/A      4  €1.1M      25   1384      53   \n",
      "\n",
      "   col-oa  col-pi col-def col-phy col-wg col-ae col-dri              Contract  \\\n",
      "0      74  230084      39      77   €67K     21      76  Jun 30, 2021 On Loan   \n",
      "1      69  231900      30      67     €0     27      70                  Free   \n",
      "2      74  237995      49      55   €15K     20      80           2019 ~ 2024   \n",
      "3      71  219736      49      62   €11K     25      76           2017 ~ 2021   \n",
      "4      78  226162      64      67   €13K     23      82           2018 ~ 2024   \n",
      "..    ...     ...     ...     ...    ...    ...     ...                   ...   \n",
      "55     68  239922      34      64    €3K     24      70           2021 ~ 2023   \n",
      "56     66  239930      63      76    €2K     24      63           2017 ~ 2023   \n",
      "57     60  239947      60      61    €2K     20      56           2020 ~ 2023   \n",
      "58     60  240041      41      43    €7K     20      65           2017 ~ 2022   \n",
      "59     66  240044      67      66    €3K     24      44           2018 ~ 2022   \n",
      "\n",
      "            Name                          Team  \n",
      "0      L. Nmecha  RSC AnderlechtJun ,  On Loan  \n",
      "1     FakePlayer                  China PRFree  \n",
      "2      D. Lainez                  Real Betis    \n",
      "3     E. Horvath              Club Brugge KV    \n",
      "4     E. Buendía                Norwich City    \n",
      "..           ...                           ...  \n",
      "55     Rui Costa                 Santa Clara    \n",
      "56      D. Rasak                 Wisła Płock    \n",
      "57      R. Meraz                 Mazatlán FC    \n",
      "58    A. Babacan              Galatasaray SK    \n",
      "59          Luan              SKN St. Pölten    \n",
      "\n",
      "[16539 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving df into a csv datbase\n",
    "final_df.to_csv(\"./FIFAPlayersAnalisis/FIFAPlayersData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALYSIS OF SOFIFA URLS\n",
    "#1-https://sofifa.com/players?&showCol%5B %5D=pi&showCol%5B %5D=ae&showCol%5B %5D=oa&showCol%5B %5D=pt&showCol%5B %5D=bp&showCol%5B %5D=gu&showCol%5B%5D=le&showCol%5B%5D=vl&showCol%5B%5D=wg&showCol%5B%5D=tt&showCol%5B%5D=pac&showCol%5B%5D=sho&showCol%5B%5D=pas&showCol%5B%5D=dri&showCol%5B%5D=def&showCol%5B%5D=phy\n",
    "#2-https://sofifa.com/players? showCol%5B0%5D=pi&showCol%5B1%5D=ae&showCol%5B2%5D=oa&showCol%5B3%5D=pt&showCol%5B4%5D=bp&showCol%5B5%5D=gu&showCol%5B6%5D=le&showCol%5B7%5D=vl&showCol%5B8%5D=wg&showCol%5B9%5D=tt&showCol%5B10%5D=pac&showCol%5B11%5D=sho&showCol%5B12%5D=pas&showCol%5B13%5D=dri&showCol%5B14%5D=def&showCol%5B15%5D=phy&offset=60\n",
    "#3-https://sofifa.com/players? showCol%5B0%5D=pi&showCol%5B1%5D=ae&showCol%5B2%5D=oa&showCol%5B3%5D=pt&showCol%5B4%5D=bp&showCol%5B5%5D=gu&showCol%5B6%5D=le&showCol%5B7%5D=vl&showCol%5B8%5D=wg&showCol%5B9%5D=tt&showCol%5B10%5D=pac&showCol%5B11%5D=sho&showCol%5B12%5D=pas&showCol%5B13%5D=dri&showCol%5B14%5D=def&showCol%5B15%5D=phy&offset=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING\n",
    "# url = 'https://sofifa.com/players? showCol%5B0%5D=pi&showCol%5B1%5D=ae&showCol%5B2%5D=oa&showCol%5B3%5D=pt&showCol%5B4%5D=bp&showCol%5B5%5D=gu&showCol%5B6%5D=le&showCol%5B7%5D=vl&showCol%5B8%5D=wg&showCol%5B9%5D=tt&showCol%5B10%5D=pac&showCol%5B11%5D=sho&showCol%5B12%5D=pas&showCol%5B13%5D=dri&showCol%5B14%5D=def&showCol%5B15%5D=phy&offset=6000'\n",
    "# soup = soup_making(url)\n",
    "\n",
    "# my_classes = find_all_classes(soup,'td')\n",
    "# classes_to_remove = ['col','col-avatar','col-comment','col-name']\n",
    "# my_classes = remove_from_my_classes(my_classes,classes_to_remove)\n",
    "\n",
    "# my_dict = create_dict(my_classes)\n",
    "\n",
    "# #~~~~~~getting team, name and contract\n",
    "# #CONTRACT\n",
    "# contract = soup.find_all('div',{'class':'sub'})\n",
    "# contract = get_text(contract)\n",
    "# contract = clean_string(contract,'\\n*')\n",
    "# #NAME AND TEAM\n",
    "# name_team_contract = soup.find_all('div',{'class':'bp3-text-overflow-ellipsis'})\n",
    "# name_team_contract = get_text(name_team_contract)\n",
    "# #NAME\n",
    "# name = name_team_contract[::2]\n",
    "# name = clean_string(name,'\\\\d|\\~')\n",
    "# #TEAM\n",
    "# team = name_team_contract[1::2]\n",
    "# team = clean_string(team,'\\n*|\\\\d|\\~')\n",
    "# #adding them to the dict\n",
    "# my_dict['Contract'] = contract\n",
    "# my_dict['Name'] = name\n",
    "# my_dict['Team'] = team\n",
    "# #~~~~Creating data frame with all the data\n",
    "# df = pd.DataFrame(my_dict)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTING OF DATA SOTRING METHOD USING DF's\n",
    "# dff_list = []\n",
    "# d1 = {'key1': 'x1', 'key2': 'y1'}  \n",
    "# d2 = {'key1': 'x2', 'key2': 'y2'}  \n",
    "# d3 = {'key1': 'x3', 'key2': 'y3'}  \n",
    "# d4 = {'key1': 'x4', 'key2': 'y4'}  \n",
    "\n",
    "\n",
    "# dff = pd.DataFrame(d1,index=[0])\n",
    "# #print(dff)\n",
    "# dff_list.append(dff)\n",
    "# #print(dff_list)\n",
    "\n",
    "# dff = pd.DataFrame(d2,index=[0])\n",
    "# #print(dff)\n",
    "# dff_list.append(dff)\n",
    "# dff = pd.DataFrame(d3,index=[0])\n",
    "# dff_list.append(dff)\n",
    "# dff = pd.DataFrame(d4,index=[0])\n",
    "# dff_list.append(dff)\n",
    "# de = pd.concat(dff_list)\n",
    "\n",
    "# print(de)\n",
    "# print(type(de))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
