{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUNNING ALL FUNCTIONS AND IMPORTS\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "#Making Soup function\n",
    "def soup_making(url):\n",
    "    my_page = requests.get(url)\n",
    "    soup = bs(my_page.text, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "#getting the text function\n",
    "def get_text(my_list):\n",
    "    data = []\n",
    "    for item in my_list:\n",
    "        data.append(item.getText())\n",
    "    return data\n",
    "\n",
    "#finds all classes for a given tag\n",
    "def find_all_classes(my_soup,tag):\n",
    "    tags = my_soup.find_all(tag)\n",
    "    all_td_classes = set()\n",
    "    for tag in tags:\n",
    "        for c in tag.attrs['class']:\n",
    "            all_td_classes.add(c)\n",
    "    return list(all_td_classes)\n",
    "\n",
    "#creating a dict with classes names as Keys and the texts as values\n",
    "def create_dict(my_soup,classes):\n",
    "    data_dict = {}\n",
    "    for item in classes:\n",
    "        values = get_text(my_soup.find_all('td',{'class':item}))\n",
    "        data_dict.update({item:values})\n",
    "    return data_dict\n",
    "\n",
    "#clean given string\n",
    "def clean_string(my_list,string):\n",
    "    data =[]\n",
    "    for item in my_list:\n",
    "        a = re.sub(string,'',item)\n",
    "        data.append(a)\n",
    "    return data\n",
    "\n",
    "#remove undesired classes\n",
    "def remove_from_my_classes(my_classes,classes_to_remove):\n",
    "    for x in classes_to_remove:\n",
    "        my_classes.remove(x)\n",
    "    return my_classes\n",
    "\n",
    "#creates a list of urls to iterate\n",
    "def create_urls_list(url,indexes):\n",
    "    urls_list = []\n",
    "    for index in indexes:\n",
    "        current_url = url + str(index)\n",
    "        urls_list.append(current_url)\n",
    "    return urls_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING all the URLS\n",
    "#generating url indexes\n",
    "indexes = np.arange(0,17400,60)\n",
    "url = 'https://sofifa.com/players? showCol%5B0%5D=pi&showCol%5B1%5D=ae&showCol%5B2%5D=oa&showCol%5B3%5D=pt&showCol%5B4%5D=bp&showCol%5B5%5D=gu&showCol%5B6%5D=le&showCol%5B7%5D=vl&showCol%5B8%5D=wg&showCol%5B9%5D=tt&showCol%5B10%5D=pac&showCol%5B11%5D=sho&showCol%5B12%5D=pas&showCol%5B13%5D=dri&showCol%5B14%5D=def&showCol%5B15%5D=phy&offset='\n",
    "urls = create_urls_list(url,indexes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION THAT SCRAPES ALL SOFIFA PAGES\n",
    "def create_final_df(urls):\n",
    "    df_list = []\n",
    "    for url in urls:\n",
    "        my_dict = {}\n",
    "        soup = soup_making(url)\n",
    "        my_classes = find_all_classes(soup,'td')\n",
    "        classes_to_remove = ['col','col-avatar','col-comment','col-name']\n",
    "        my_classes = remove_from_my_classes(my_classes,classes_to_remove)\n",
    "        my_dict = create_dict(soup, my_classes)\n",
    "        #~~~~~~getting team, name and contract\n",
    "        #CONTRACT\n",
    "        contract = soup.find_all('div',{'class':'sub'})\n",
    "        contract = get_text(contract)\n",
    "        contract = clean_string(contract,'\\n*')\n",
    "        #NAME AND TEAM\n",
    "        name_team_contract = soup.find_all('div',{'class':'bp3-text-overflow-ellipsis'})\n",
    "        name_team_contract = get_text(name_team_contract)\n",
    "        #NAME\n",
    "        name = name_team_contract[::2]\n",
    "        name = clean_string(name,'\\\\d|\\~')\n",
    "        #TEAM\n",
    "        team = name_team_contract[1::2]\n",
    "        team = clean_string(team,'\\n*|\\\\d|\\~')\n",
    "        #adding them to the dict\n",
    "        my_dict['Contract'] = contract\n",
    "        my_dict['Name'] = name\n",
    "        my_dict['Team'] = team\n",
    "        df = pd.DataFrame(my_dict)\n",
    "        df_list.append(df)\n",
    "        sleep(randint(2,10))\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "final_df = create_final_df(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    col-pi col-tt col-gu        col-le col-pac col-sho  col-vl col-bp col-wg  \\\n",
      "0   245940   1901     10           N/A      89      71  €12.5M     ST   €17K   \n",
      "1   232488   1674      6  Jun 30, 2021      68      35  €20.5M     CB   €55K   \n",
      "2   211302   1762      0           N/A      72      70   €1.8M     ST   €13K   \n",
      "3   235212   2150      5           N/A      94      71    €56M     RM   €90K   \n",
      "4   202811   1442      2           N/A      83      83    €33M     GK   €64K   \n",
      "..     ...    ...    ...           ...     ...     ...     ...    ...    ...   \n",
      "55  246454   1330     17           N/A      63      27   €550K     CB    €4K   \n",
      "56  246549   1560      7           N/A      54      41   €750K     CB    €4K   \n",
      "57  246657    975      7           N/A      71      68   €2.4M     GK    €3K   \n",
      "58  246667   1515      6           N/A      63      34   €2.3M     CB    €8K   \n",
      "59  246709   1376      8           N/A      56      31   €675K     CB    €2K   \n",
      "\n",
      "   col-def col-phy col-ae col-pas col-dri col-oa col-pt              Contract  \\\n",
      "0       52      70     20      61      80     75     85           2019 ~ 2024   \n",
      "1       79      79     22      45      56     78     84  Jun 30, 2021 On Loan   \n",
      "2       24      61     30      57      73     71     71           2020 ~ 2023   \n",
      "3       73      77     21      77      83     83     88           2020 ~ 2025   \n",
      "4       58      82     27      82      83     83     85           2020 ~ 2024   \n",
      "..     ...     ...    ...     ...     ...    ...    ...                   ...   \n",
      "55      59      62     19      39      45     59     76           2018 ~ 2021   \n",
      "56      58      75     23      53      54     62     69           2020 ~ 2023   \n",
      "57      30      69     22      65      67     69     76           2018 ~ 2022   \n",
      "58      68      79     22      43      48     70     76           2019 ~ 2022   \n",
      "59      60      66     20      45      46     61     69           2019 ~ 2023   \n",
      "\n",
      "               Name                    Team  \n",
      "0    S. Wamangituka         VfB Stuttgart    \n",
      "1         C. Romero  AtalantaJun ,  On Loan  \n",
      "2       G. Lapadula             Benevento    \n",
      "3         A. Hakimi                 Inter    \n",
      "4       E. Martínez           Aston Villa    \n",
      "..              ...                     ...  \n",
      "55         D. Revan           Aston Villa    \n",
      "56          M. Siby  RC Strasbourg Alsace    \n",
      "57    Álvaro Vallés         UD Las Palmas    \n",
      "58       J. Novillo           Racing Club    \n",
      "59       A. Skipper            Brøndby IF    \n",
      "\n",
      "[16519 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving df into a csv datbase\n",
    "final_df.to_csv(\"./FIFAPlayersData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALYSIS OF SOFIFA URLS\n",
    "#1-https://sofifa.com/players?&showCol%5B %5D=pi&showCol%5B %5D=ae&showCol%5B %5D=oa&showCol%5B %5D=pt&showCol%5B %5D=bp&showCol%5B %5D=gu&showCol%5B%5D=le&showCol%5B%5D=vl&showCol%5B%5D=wg&showCol%5B%5D=tt&showCol%5B%5D=pac&showCol%5B%5D=sho&showCol%5B%5D=pas&showCol%5B%5D=dri&showCol%5B%5D=def&showCol%5B%5D=phy\n",
    "#2-https://sofifa.com/players? showCol%5B0%5D=pi&showCol%5B1%5D=ae&showCol%5B2%5D=oa&showCol%5B3%5D=pt&showCol%5B4%5D=bp&showCol%5B5%5D=gu&showCol%5B6%5D=le&showCol%5B7%5D=vl&showCol%5B8%5D=wg&showCol%5B9%5D=tt&showCol%5B10%5D=pac&showCol%5B11%5D=sho&showCol%5B12%5D=pas&showCol%5B13%5D=dri&showCol%5B14%5D=def&showCol%5B15%5D=phy&offset=60\n",
    "#3-https://sofifa.com/players? showCol%5B0%5D=pi&showCol%5B1%5D=ae&showCol%5B2%5D=oa&showCol%5B3%5D=pt&showCol%5B4%5D=bp&showCol%5B5%5D=gu&showCol%5B6%5D=le&showCol%5B7%5D=vl&showCol%5B8%5D=wg&showCol%5B9%5D=tt&showCol%5B10%5D=pac&showCol%5B11%5D=sho&showCol%5B12%5D=pas&showCol%5B13%5D=dri&showCol%5B14%5D=def&showCol%5B15%5D=phy&offset=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING\n",
    "# url = 'https://sofifa.com/players? showCol%5B0%5D=pi&showCol%5B1%5D=ae&showCol%5B2%5D=oa&showCol%5B3%5D=pt&showCol%5B4%5D=bp&showCol%5B5%5D=gu&showCol%5B6%5D=le&showCol%5B7%5D=vl&showCol%5B8%5D=wg&showCol%5B9%5D=tt&showCol%5B10%5D=pac&showCol%5B11%5D=sho&showCol%5B12%5D=pas&showCol%5B13%5D=dri&showCol%5B14%5D=def&showCol%5B15%5D=phy&offset=6000'\n",
    "# soup = soup_making(url)\n",
    "\n",
    "# my_classes = find_all_classes(soup,'td')\n",
    "# classes_to_remove = ['col','col-avatar','col-comment','col-name']\n",
    "# my_classes = remove_from_my_classes(my_classes,classes_to_remove)\n",
    "\n",
    "# my_dict = create_dict(my_classes)\n",
    "\n",
    "# #~~~~~~getting team, name and contract\n",
    "# #CONTRACT\n",
    "# contract = soup.find_all('div',{'class':'sub'})\n",
    "# contract = get_text(contract)\n",
    "# contract = clean_string(contract,'\\n*')\n",
    "# #NAME AND TEAM\n",
    "# name_team_contract = soup.find_all('div',{'class':'bp3-text-overflow-ellipsis'})\n",
    "# name_team_contract = get_text(name_team_contract)\n",
    "# #NAME\n",
    "# name = name_team_contract[::2]\n",
    "# name = clean_string(name,'\\\\d|\\~')\n",
    "# #TEAM\n",
    "# team = name_team_contract[1::2]\n",
    "# team = clean_string(team,'\\n*|\\\\d|\\~')\n",
    "# #adding them to the dict\n",
    "# my_dict['Contract'] = contract\n",
    "# my_dict['Name'] = name\n",
    "# my_dict['Team'] = team\n",
    "# #~~~~Creating data frame with all the data\n",
    "# df = pd.DataFrame(my_dict)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTING OF DATA SOTRING METHOD USING DF's\n",
    "# dff_list = []\n",
    "# d1 = {'key1': 'x1', 'key2': 'y1'}  \n",
    "# d2 = {'key1': 'x2', 'key2': 'y2'}  \n",
    "# d3 = {'key1': 'x3', 'key2': 'y3'}  \n",
    "# d4 = {'key1': 'x4', 'key2': 'y4'}  \n",
    "\n",
    "\n",
    "# dff = pd.DataFrame(d1,index=[0])\n",
    "# #print(dff)\n",
    "# dff_list.append(dff)\n",
    "# #print(dff_list)\n",
    "\n",
    "# dff = pd.DataFrame(d2,index=[0])\n",
    "# #print(dff)\n",
    "# dff_list.append(dff)\n",
    "# dff = pd.DataFrame(d3,index=[0])\n",
    "# dff_list.append(dff)\n",
    "# dff = pd.DataFrame(d4,index=[0])\n",
    "# dff_list.append(dff)\n",
    "# de = pd.concat(dff_list)\n",
    "\n",
    "# print(de)\n",
    "# print(type(de))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
